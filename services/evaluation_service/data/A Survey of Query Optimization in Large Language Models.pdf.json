[
  {
    "text": "_Query Optimization_ (QO) refers to techniques aimed at enhancing the efficiency and quality of Large Language Models (LLMs) in understanding and answering queries, especially complex ones in scenarios like Retrieval-Augmented Generation (RAG). Specifically, RAG mitigates the limitations of LLMs by dynamically retrieving and leveraging up-to-date relevant information, which provides a cost-effective solution to the challenge of LLMs producing plausible but potentially inaccurate responses. Recently, as RAG evolves and incorporates multiple components that influence its performance, QO has emerged as a critical element, playing a pivotal role in determining the effectiveness of RAG’s retrieval stage in accurately sourcing the necessary multiple pieces of evidence to answer queries correctly. In this paper, we trace the evolution of QO techniques by summarizing and analyzing significant studies. Through an organized framework and categorization, we aim to consolidate existing QO techniques in RAG, elucidate their technological foundations, and highlight their potential to enhance the versatility and applications of LLMs.",
    "metadata": {
      "page_number": 1,
      "header": "Abstract",
      "chunk_index": 1,
      "file_path": "A Survey of Query Optimization in Large Language Models.pdf",
      "token_count": 1136
    }
  },
  {
    "text": "Large Language Models (LLMs) have made impressive achievements (Zhao et al., 2023), yet they still encounter notable challenges, particularly in tasks that are domain-specific or heavily reliant on specialized knowledge (Kandpal et al., 2023; Gao et al., 2023b; Zhu et al., 2023b; Huang and Huang, 2024; Verma, 2024; Zhao et al., 2024; Hu and Lu, 2024; Fan et al., 2024; Wu et al., 2024; Peng et al., 2024a; Gupta et al., 2024). One prominent issue is their tendency to produce \"hallucinations\" when dealing with queries that surpass their training data or necessitate up-to-date information (Zhang et al., 2023b; Tonmoy et al., 2024). To mitigate these challenges, Retrieval-Augmented Generation(RAG)enhancesLLMsbyretrievingrelevant Figure 1: Four atomic operations in QO. segments, effectively diminishing the production of factually incorrect content. The widespread integration of RAG into LLMs has established it as a crucial technology for the advancement of query solvers and has improved the suitability of LLMs for practical, real-world applications. Since Lewis et al. (2020) introduced RAG, the field has advanced rapidly, particularly with the emergence of models like ChatGPT. Despite these developments, there is a significant gap in the literature—a thorough analysis of RAG’s underlying mechanisms and the progress made in subsequent studies is lacking. Furthermore, the field is characterized by fragmented research focuses and inconsistent terminology for similar methods, which leads to confusion. RAG typically involves several core concepts, including but not limited to query optimization, information retrieval, and response generation (Zhu et al., 2023b; Huang and Huang, 2024; Verma, 2024). Among these, query optimization plays a crucial role in directly determining the relevance of the retrieved information and consequently impactsthequalityofthefinalresponse.Although",
    "metadata": {
      "page_number": 1,
      "header": "1 Introduction",
      "chunk_index": 2,
      "file_path": "A Survey of Query Optimization in Large Language Models.pdf",
      "token_count": 1897
    }
  },
  {
    "text": "query optimization in retrieval-augmented large language models (LLMs) has experienced rapid growth, there has been a lack of systematic synthesis to clarify its broader trajectory. This survey endeavors to fill this gap by mapping out the query optimization process in retrieval-augmented LLMs, charting its evolution, and anticipating future developments. We consider both technical paradigms and research methods, summarizing four main approaches identified in recent LLM-based RAG studies: _Expansion_, _Disambiguation_, _Decomposition_, and _Abstraction_, as shown in Figure 1, and then categorize the corresponding atomic operations for query optimization and map them accordingly. We classify the difficulty of most queries into four types: those that can be solved with a single piece of explicit evidence, those requiring multiple pieces of explicit evidence, those solvable with a single piece of implicit evidence, and those needing multiple pieces of implicit evidence. We then map these queries to different optimization operations respectively for ease of explanation, as shown in Figure 2. Next, we briefly introduce each type of query and the corresponding optimization method, as illustrated in Figure 3. Overall, this paper aims to meticulously compile and categorize the foundational technical concepts, historical developments, and the range of query optimization methodologies and applications that have emerged since the advent of LLMs. It is designed to equip readers and professionals with a detailed and structured understanding of query optimization in retrieval-augmented LLMs, illuminating the evolution of these techniques and speculating on upcoming trends and innovations. Query optimization techniques summarized in this paper may involve multiple scenarios, including but not limited to retrieval-augmented generation, question answering, etc. Therefore, we uniformly adopt the term \"query\" to represent terms such as \"query\", \"question\", and \"problem\" in the subsequent content. Additionally, this survey is organized as follows: Section 2 introduces the stratification of query optimization. The subsequent sections delve into key techniques in query optimization: Section 2.1 explores query expansion, which is further divided into internal expansion (Section 2.1.1) and external expansion (Section 2.1.2). Section 2.2 discusses query decomposition. Section 2.3 and Section 3 focus on disambiguation and abstraction. Section 4 addressesthechallengesandfuturedirectionsin this field. Finally, the conclusion and limitations are presented in Section 5 and Section 6.",
    "metadata": {
      "page_number": 1,
      "header": "Multiple Pieces of Implicit Evidence",
      "chunk_index": 3,
      "file_path": "A Survey of Query Optimization in Large Language Models.pdf",
      "token_count": 2600
    }
  },
  {
    "text": "Query optimization is crucial for enhancing the effectiveness and precision of retrieval-augmented generation using large language models. By refining users’ original queries, this process addresses several challenges, including ambiguous semantics, complex requirements, and discrepancies in relevance between the query and target documents. Effective query optimization demands a profound understanding of user intent and query context, especially when dealing with intricate or multifaceted inquiries. When implemented successfully, it significantly improves problem-solving performance, substantially impacting the quality of the model’s generated outputs. Ultimately, this enhancement in query processing leads to more accurate and contextually appropriate responses, elevating the overall user experience and increasing the utility of LLMs across various applications.",
    "metadata": {
      "page_number": 2,
      "header": "2 Stratification of Query Optimization",
      "chunk_index": 4,
      "file_path": "A Survey of Query Optimization in Large Language Models.pdf",
      "token_count": 874
    }
  },
  {
    "text": "Query Expansion techniques (Azad and Deepak, 2019) are critical in enhancing the performance of retrieval-augmented generation, particularly when integrated with LLMs (Weller et al., 2024). Based on the different sources of knowledge, we broadly categorize it into internal expansion and external expansion. The former focuses on maximizing the value of existing information in the original query or the used LLM without relying on external knowledge sources., while the latter introduces supplementary data from outside sources (e.g., Web or Knowledge base) to fill gaps, provide additional context, or broaden the scope of the content.",
    "metadata": {
      "page_number": 2,
      "header": "2.1 Query Expansion",
      "chunk_index": 5,
      "file_path": "A Survey of Query Optimization in Large Language Models.pdf",
      "token_count": 637
    }
  },
  {
    "text": "In recent years, researchers have developed various query expansion techniques to enhance information retrieval systems by leveraging LLMs. One of the early approaches is G EN R EAD (Yu et al., 2023a), which employs a well-designed instruction to prompt LLMs to generate contextual documents based on the initial query. These generated documents are then read by the LLM to produce the final response, effectively bridging the gap between query understanding and answer generation. Building upon the concept of query expansion, Q UERY 2D OC (Wang et al., 2023b) introduces a simpleyeteffectiveapproachtoimproveboth Figure 2: Classification of query optimization techniques in detail. sparse and dense retrieval systems. By generating pseudo-documents through the few-shot prompting of LLMs, the original query is expanded with these generated documents. Since LLMs are trained on web-scale text corpora, these pseudo-documents often contain highly relevant information that aids in disambiguating queries and guiding retrievers toward more pertinent results. In a similar vein, R E F EED (Yu et al., 2023b) tackles LLM limitations efficiently and cost-effectively by first generating initial outputs. It then retrieves relevant information from large document collections using a retrieval model and incorporates this information into the in-context demonstration to refine the output. This iterative process enhances the quality of the final response by grounding it in retrieved data. I NTE R (Feng et al., 2024) presents an interactive retrievalframeworkwhereretrievalmodelsexpand the knowledge within queries by utilizing LLMgenerated knowledge collections. Concurrently, LLMs enhance prompt formulation by leveraging retrieved documents, creating a synergistic loop between the retrieval models and the LLMs for improved information access. Approaching the challenge from a different angle, H Y DE (Gao et al., 2023a) employs a zeroshot prompt with a language model to generate a hypothetical document that captures relevant patterns, even if it contains \"hallucinations.\" An unsupervised contrastive encoder then encodes this document into an embedding vector to identify a neighborhood in the corpus embedding space. By retrieving similar real documents based on vector similarity, H Y DE grounds the generated content to the actual corpus, with the encoder’s dense bottleneck filtering out inaccuracies. FLARE (Jiang etal., 2023)introducesaniterativeanticipation Figure 3: Taxonomy tree of core techniques of query optimization. mechanism where, based on the original query, it predicts future content and retrieves relevant information to enhance retrieval performance. If the generated temporary next sentence contains lowconfidence tokens, FLARE treats it as a new query to retrieve additional documents, repeating this process until a satisfactory answer is obtained. Expanding on query generation, MILL (Jia et al., 2024) proposes a query–query–document generation approach that leverages the zero-shot reasoning capabilities of LLMs to produce diverse subqueries and corresponding documents. A mutual verification process then synergizes the generated and retrieved documents, leading to optimal expansionandcomprehensiveretrievalresults. To further refine retrieval performance, G EN  QRE NSEMBLE (Dhole and Agichtein, 2024) suggests an ensemble-based prompting technique that uses paraphrases of a zero-shot instruction to generate multiple sets of keywords. By combining these keyword sets, the method enhances retrieval efficacy through diversity and redundancy. Lastly, ERRR (Cong et al., 2024) emphasizes the extraction of parametric knowledge from LLMs and the refinement of these queries using a specialized query optimizer. This approach ensures that only the most pertinent information is retrieved, which is essential for generating accurate and rele vantresponses.",
    "metadata": {
      "page_number": 2,
      "header": "2.1.1 Internal Expansion",
      "chunk_index": 6,
      "file_path": "A Survey of Query Optimization in Large Language Models.pdf",
      "token_count": 3890
    }
  },
  {
    "text": "External Expansion is a sophisticated process that significantly enhances document content by seamlessly integrating pertinent information from diverse external sources. This methodology augments the overall context, depth, and accuracy of the document corpus. The enrichment process involves strategically incorporating authoritative facts, up-to-date data points, and relevant contextual knowledge derived from a wide array of external datasets, knowledge bases, and curated information repositories. LameR (Shen et al., 2024a) augments a query with its potential answers by prompting LLMs with a combination of the query and the question’s indomain candidates. These candidates, regardless of whether they are correct or incorrect, are obtained through a standard retrieval procedure on the target collection. GuideCQR (Park and Lee, 2024) refines queries for conversational query reformulation by leveraging key information from the initially retrieved documents. CSQE (Lei et al., 2024) promotes the incorporation of knowledge embedded within the corpus and leverages the relevance-assessing capabilities of LLMs to systematically identify pivotal sentences in the initially retrieved documents. These corpus-derived texts are then used to expand the query, along with LLMempowered expansions, enhancing the relevance prediction between the query and the target documents. MUGI (Zhang et al., 2024b) explores and leverages LLMs to generate multiple pseudo references, integrating them with queries to enhance both sparse and dense retrievers.",
    "metadata": {
      "page_number": 2,
      "header": "2.1.2 External Expansion",
      "chunk_index": 7,
      "file_path": "A Survey of Query Optimization in Large Language Models.pdf",
      "token_count": 1547
    }
  },
  {
    "text": "For complex queries, simply searching with the original query often fails to retrieve adequate information. It is crucial for LLMs to first decompose such queries into simpler, answerable sub-queries, and then search for information relevant to these sub-components. By integrating the responses to these sub-queries, LLMs are able to construct a comprehensive response to the original query. One such method is the Demonstrate Search Pre dict (DSP) framework (Khattab et al., 2022), which relies on passing natural language texts through sophisticated pipelines between an LLM and a retrieval model (RM). DSP can express high-level programs that bootstrap pipeline-aware demonstrations,searchforrelevantpassages,andgener ate grounded predictions, systematically breaking down problems into small transformations that the LLM and RM can handle more reliably. Similarly, techniques like L EAST  - TO -M OST (Zhou et al., 2023) prompting utilize few-shot prompts to first decompose a complex problem into a series of simpler subproblems and then solve them in sequence. P LAN - AND -S OLVE (Wang et al., 2023a) prompting involves devising a plan to divide the entire task into smaller subtasks and then carrying out these subtasks according to the plan. These approaches emphasize the importance of decomposition in handling complex queries, allowing models to process each component effectively. SELF-ASK (Press et al., 2023) introduces the concept of the compositionality gap, which describes the fraction of compositional queries that the model answers incorrectly out of all the compositional queries for which the model answers the sub-queries correctly. This highlights the challenges LLMs face in integrating answers from subqueries to solve more complex queries. To address retrieval challenges, approaches like EAR (Chuang et al., 2023) apply a query expansion model to generate a diverse set of queries, using a query reranker to select those that could lead to better retrieval results. Correction of Knowledge (C O K) (Li et al., 2024) first proposes and prepares several preliminary rationales and answers while identifying the relevant knowledge domains. If there is no majority consensus among the answers, C O K corrects the rationales step by step by adapting knowledge from the identified domains, serving as a better foundation for the final response consolidation. In the realm of transferring abilities to LLMs, ICAT (V et al., 2023) induces reasoning capabilities without any LLM fine-tuning or manual annotation of in-context samples. It transfers the ability to decompose complex queries into simpler ones or generate step-by-step rationales by carefully selecting from available data sources of related tasks. R E A CT (Yao et al., 2023) introduces a paradigm to combine reasoning and acting with LLMs for solving diverse language reasoning and decisionmaking tasks. R E A CT prompts LLMs to generate both verbal reasoning traces and actions on a task in an interleaved manner. This allows the model to perform dynamic reasoning to create, maintain, and adjust high-level plans for acting (\"reason to act\"), while also interacting with external environments(e.g.,Wikipedia)toincorporateadditional information into reasoning (\"act to reason\"). Approaches like A UTO PRM (Chen et al., 2024) and RA-ISF (Liu et al., 2024) employ query decomposition to handle complex queries. Chen et al. (2024) first decomposes complex problems into more manageable sub-queries with a controllable granularity switch, then sequentially apply reinforcement learning to iteratively improve the subquery solver. Liu et al. (2024) mitigates the impact of irrelevant prompts by iteratively addressing sub-queries while integrating text relevance with self-knowledge answering capabilities. The process involves breaking down the initial multi-turn query into single-turn queries, addressing each subtask independently, and then synthesizing these responses to resolve the initial query. Other methods enhance models by equipping them with capabilities for explicit rewriting, decomposition, and disambiguation, such as RQ-RAG. LPKG (Wang et al., 2024b) enhances the query planning capabilities of LLMs by grounding predefined patterns in an open-domain knowledge graph to extract numerous instances, which are then verbalized into complex queries and corresponding sub-queries in natural language. Techniques like ALTER (Zhang et al., 2024a) and IM-RAG (Yang et al., 2024) focus on enhancing retrieval and reasoning processes. Specifically, ALTER employs a question augmentor to enhance the original question by generating multiple subqueries, each examining the original question from different perspectives, for handling complex table reasoning tasks. IM-RAG introduces a Refiner that improves the outputs from the Retriever, effectively bridging the gap between the Reasoner and information retrieval modules with varying capabilities and fostering multi-round communications. REAPER (Joshi et al., 2024), a reasoning-based planner, is designed for efficient retrieval required for complex queries. Using a single and smaller LLM, REAPER generates a plan that includes the tools to call, the order in which they should be called, and the arguments for each tool. Building on previous studies, H I RAG (Zhang et al., 2024d) decomposes the original query into multi-hop queries. Each sub-query is answered based on retrieved knowledge, and the answers are then integrated using the Chain-of-Thought (CoT) approach to derive the final answer. MQA-KEAL (Ali et al., 2024) stores knowledge edits as structured knowledge units in external memory. To solvemulti-hopqueries,itfirstusestaskdecompo sition to break the query into smaller sub-problems. For each sub-problem, it iteratively queries the external memory and/or the target LLM to generate the final response. Recent methods like R ICH RAG (Wang et al., 2024c) and C ON TR E G EN (Roy et al., 2024) further improve the retrieval process. R ICH RAG introduces a sub-aspect explorer to dissect input queries and uncover their latent facets. This is integrated with a multi-faceted retriever, which curates a diverse corpus of external documents pertinent to these identified sub-aspects to answer queries. C ON TR E G EN proposes a context-driven, tree-structured retrieval approach to enhance the depth and relevance of retrieved content. It incorporates a hierarchical, top-down in-depth exploration of query facets with a systematic bottom-up synthesis, ensuring comprehensive coverage and coherent integration of multifaceted information. P LAN ×RAG (Verma et al., 2024) formulates a comprehensive reasoning plan represented as a directed acyclic graph (DAG). This reasoning DAG decomposes the main query into interrelated atomic sub-queries, providing a computational structure that enables efficient information sharing between sub-queries. RAG-S TAR (Jiang et al., 2024) seamlessly integrates retrieved information to guide a tree-based deliberative reasoning process, leveraging the inherent knowledge of LLMs. By utilizing Monte Carlo Tree Search, RAG-S TAR iteratively plans intermediate sub-queries and generates answers for reasoning based on the capabilities of the LLM itself.",
    "metadata": {
      "page_number": 2,
      "header": "2.2 Question Decomposition",
      "chunk_index": 8,
      "file_path": "A Survey of Query Optimization in Large Language Models.pdf",
      "token_count": 7241
    }
  },
  {
    "text": "For ambiguous queries with multiple possible answers, relying solely on the original query for information retrieval is inadequate. To deliver complete and nuanced responses, LLMs must learn to clarify the query by identifying the user’s intent and then formulate a more targeted search query. After gathering relevant information, LLMs can provide a detailed and comprehensive response. There are mainly two types of approaches for query disambiguation. One is when the query itself is ambiguous, and the other is for multi-turn queries, where it’s necessary to rewrite the query by incorporating historical dialogue content to achieve disambiguation (Peng et al., 2024b; Mao et al., 2024). Ling et al. (2023) early introduces a deductive reasoning format based on the natural language thatdecomposesthereasoningverificationprocess into a series of step-by-step subprocesses. Each subprocess receives only the necessary context and premises, allowing LLMs to generate precise reasoning steps that are rigorously grounded on prior ones. This approach empowers language models to conduct reasoning self-verification sequentially, significantly enhancing the rigor and trustworthiness of the generated reasoning steps. Building upon the refinement of model reasoning, E CHO P ROMPT (Mekala et al., 2024) introduces a query-rephrasing subtask by employing prompts like “ _Let’s repeat the query and also think_ _step by step._ ”. This encourages the model to restate the query in its own words before engaging in reasoning, ensuring better understanding and consistency. Importantly, the prompt used for answer extraction remains consistent across all zero shot methodologies. T O C (Kim et al., 2023) recursively builds a tree of disambiguations for ambiguous queries by utilizing few-shot prompting and external knowledge. It retrieves relevant facts to generate a comprehensive long-form answer based on this tree, thus providing more accurate and detailed responses. I NFO CQR (Ye et al., 2023) introduces a novel \"rewrite-then-edit\" framework, where LLMs first rewrite the original query and then revise the rewritten query to eliminate ambiguities. The well-designed instructions independently guide the LLMs through the rewriting and editing tasks, resulting in more informative and unambiguous queries. To further manipulate the disambiguated query, A DA QR (Zhang et al., 2024c) proposes a novel preference optimization approach, which aims to tailor rewriters to better suit retrievers by utilizing conversation answers to model retrievers’ preferences. Specifically, the trained rewriter generates several rewrites, which are then used as queries to retrieve passages from a target retriever. Then, A DA QR calculates the conditional probability of the answer given each retrieved passage and the conversation, obtaining the marginal probability of the answer by marginalizing over the set of passages. This marginal probability serves as a reward that quantifies the retrievers’ preferences over rewrites and pairs these rewrites based on their rewards to optimize the trained rewriter using direct preference optimization. M A F E R W (Wang et al., 2024e) improves the RAG performance by integrating multi-aspect feedback from both the retrieved documents and the generatedresponsesasrewardstoexploretheopti mal query rewriting strategy. This approach leverages comprehensive feedback to enhance the effectiveness of query rewriting. CHIQ leverages the NLP capabilities of LLMs, such as resolving coreference relations and expanding context, to reduce ambiguity in conversational history. This enhancement improves the relevance of the generated search queries. We investigate various methods for integrating refined conversational history into existing frameworks, including ad-hoc query rewriting, generating pseudo-supervision signals for fine-tuning query rewriting models, and combining both approaches.",
    "metadata": {
      "page_number": 2,
      "header": "2.3 Query Disambiguation",
      "chunk_index": 9,
      "file_path": "A Survey of Query Optimization in Large Language Models.pdf",
      "token_count": 3918
    }
  },
  {
    "text": "For complex multi-hop queries, sequential decomposition may not yield accurate answers and can even complicate the query further. Humans often step back and perform abstractions to arrive at highlevel principles to solve complex queries, reducing the chance of making errors in the intermediate reasoning steps (Zheng et al., 2024). S TEP -B ACK (Zheng et al., 2024) manipulates the initial query using meticulously designed prompts that steer the LLM’s reasoning process. This ensures that the outputs are more closely aligned with the idea behind the original query, especially for tasks requiring complex reasoning. Building upon the idea of guiding reasoning through abstraction, (Zhou et al., 2024) requires LLMs to engage in conceptual reasoning with abstract queries, producing solutions within a verifiable symbolic space. This promotes a deeper understanding and handling of abstract concepts. C O A (Gao et al., 2024) abstracts the general CoT reasoning into a reasoning chain with abstract variables. This enables LLMs to solve queries by utilizing domain-specialized tools, such as calculation results from a calculator or relevant articles retrieved from web search engines. Similarly, A O T (Hong et al., 2024) utilizes an abstract skeletal framework to structure the entire reasoning process, potentially unlocking the key to eliciting abstract reasoning. Unlike the unconstrained CoT, the A O T format explicitly integrates different levels of abstraction throughout the reasoning process. At each higher level, the abstraction is a distilled version of the lower level, containing fewer concrete details while clearly stating the objective and functionality of each reasoning step. Inaddition, Baeketal. (2024)generatesahigher level of abstraction information that serves as the contextual background for the existing query. This approach enriches the direct information about the query object within the initial query, providing a more comprehensive understanding. Focusing on multi-faceted queries, MA-RIR (Korikov et al., 2024) defines a query aspect as a sub-span of a multi-aspect query that represents a distinct topic or facet within the query. This allows for more focused and effective reasoning across different aspects of a complex query. To further improve reasoning efficiency and accuracy, M ETA -R EASONING (Wang et al., 2024d) seeks to deconstruct the semantics of entities and operations within each query into generic symbolic representations. This methodology allows LLMs to learn generalized reasoning patterns across a variety of semantically complex scenarios. Recently, recognizing the role of explicit logical guidance, R ULE RAG (Anonymous, 2024) observes that widespread logical rules can guide people to accomplish given tasks. It proposes a new approach that can recall documents supporting queries logically in the directions of these rules, generating final responses based on retrieved information and attributable rules. S IM GRAG (Cai et al., 2024) effectively tackles the challenge of aligning query texts with knowledge graph (KG) structures through a two-stage process. First, in the query-to-pattern stage, it uses a large language model to transform queries into desired graph patterns. Second, in the pattern-to-subgraph stage, it quantifies the alignment between these patterns and candidate subgraphs using a graph semantic distance (GSD).",
    "metadata": {
      "page_number": 2,
      "header": "3 Query Abstraction",
      "chunk_index": 10,
      "file_path": "A Survey of Query Optimization in Large Language Models.pdf",
      "token_count": 3397
    }
  },
  {
    "text": "A promising approach to improving reasoning in LLMs is the use of process reward models (PRMs) (Ma et al., 2023a; Setlur et al., 2024). PRMs provide feedback at each step of a multi-step reasoning process, potentially enhancing credit assignment compared to outcome reward models (ORMs) that only provide feedback at the final step. However, the processes in PRMs generated by chainof-thought (CoT) prompting methods are usually unpredictable and make it difficult to find the optimal path. Utilizing the optimal path for optimizing complex queries to construct query-centric process rewardmodelsmaybeasimplerandmoreeffective strategy, which means rewards are provided at each sub-query of a multi-step reasoning process.",
    "metadata": {
      "page_number": 2,
      "header": "4 Challenges and Future Directions 4.1 Query-Centric Process Reward Model",
      "chunk_index": 11,
      "file_path": "A Survey of Query Optimization in Large Language Models.pdf",
      "token_count": 721
    }
  },
  {
    "text": "Currently, the notable lack of benchmarks for query optimization hinders the consistent assessment and comparison of different query optimization techniques across various scenarios. Typically, the issue is especially prominent in complex contexts, such as optimizing queries for search within multiturn retrieval-augmented dialogues and in the decomposition of intricate problems. Developing comprehensive evaluation frameworks and benchmarks may significantly benefit advancements in query optimization techniques, such as existing benchmarks in RAG (Kuo et al., 2024; Xie et al., 2024; Han et al., 2024).",
    "metadata": {
      "page_number": 8,
      "header": "4.2 Query Optimization Benchmark",
      "chunk_index": 12,
      "file_path": "A Survey of Query Optimization in Large Language Models.pdf",
      "token_count": 607
    }
  },
  {
    "text": "Many existing methods fail to pursue the most optimal query optimization paths, relying instead on strategies akin to exhaustive enumeration. This kind of strategy leads to increased computational time and higher search costs, as the system expends resources exploring numerous non-optimal paths. Additionally, it may introduce inconsistent or irrelevant search information, potentially impacting the overall quality and reliability of the results. Future research should focus on designing efficient algorithms capable of identifying optimal optimization pathways without the need for exhaustive search. Such advancements would reduce time and resource expenditures while enhancing the consistency and accuracy of query optimization outcomes. For example, query decomposition can further be categorized into parallel decomposition and sequential decomposition. Sequential decomposition typically corresponds to multi-hop queries. The reason for this classification is that parallel decomposition usually does not increase additional search time, while sequential decomposition requires iterative searching to solve dependent queries one by one, which typically increases search time as the number of hops increases.",
    "metadata": {
      "page_number": 8,
      "header": "4.3 Improving Query Optimization Efficiency and Quality",
      "chunk_index": 13,
      "file_path": "A Survey of Query Optimization in Large Language Models.pdf",
      "token_count": 1216
    }
  },
  {
    "text": "A typical paradigm of prompting-based methods involves providing LLMs with several ground-truth optimizingcases(optional)andataskdescription for the query optimizer. Although LLMs are capable of identifying the potential user intents of a query, they lack awareness of the retrieval quality resulting from the optimized query. This disconnect can result in optimized queries that appear correct but produce unsatisfactory ranking results. While some existing studies have utilized reinforcement learning to adjust the query optimization process based on generation results, a substantial realm of research remains unexplored concerning the integration of ranking results.",
    "metadata": {
      "page_number": 8,
      "header": "4.4 Enhancing Query Optimization via Post-Performance",
      "chunk_index": 14,
      "file_path": "A Survey of Query Optimization in Large Language Models.pdf",
      "token_count": 671
    }
  },
  {
    "text": "This in-depth analysis explores the domain of query optimization techniques, with a focus on their application to retrieval-augmented LLMs. Our study encompasses a broad range of optimization methods, providing a comprehensive understanding of the field. By examining the complexities of query optimization, we identify the key challenges and opportunities that arise in this area. As research in this field continues to advance, the development of specialized methodologies tailored to the needs of retrieval-augmented LLMs is crucial for unlocking their full potential across various domains. This survey aims to serve as a valuable resource for retrieval-augmented LLMs, providing a detailed overview of the current landscape and encouraging further investigation into this vital topic.",
    "metadata": {
      "page_number": 9,
      "header": "5 Conclusion",
      "chunk_index": 15,
      "file_path": "A Survey of Query Optimization in Large Language Models.pdf",
      "token_count": 789
    }
  },
  {
    "text": "The main goal of this paper is to provide a survey of the existing retrieval-augmented LLMs. Since we do not propose new models, there are no potential social risks to the best of our knowledge. Our work may benefit the research community by providing more introspection into the current state-of-the-art retrieval-augmented LLMs.",
    "metadata": {
      "page_number": 9,
      "header": "6 Limitations",
      "chunk_index": 16,
      "file_path": "A Survey of Query Optimization in Large Language Models.pdf",
      "token_count": 330
    }
  },
  {
    "text": "Muhammad Asif Ali, Nawal Daftardar, Mutayyaba Wa[heed, Jianbin Qin, and Di Wang. 2024. Mqa-keal:](https://arxiv.org/abs/2409.12257) [Multi-hop question answering under knowledge edit-](https://arxiv.org/abs/2409.12257) [ing for arabic language.](https://arxiv.org/abs/2409.12257) _Preprint_, arXiv:2409.12257. [Anonymous. 2024. RuleRAG: Rule-guided retrieval-](https://openreview.net/forum?id=zl3nFqY8l1) [augmented generation with language models for ques-](https://openreview.net/forum?id=zl3nFqY8l1) [tion answering. In](https://openreview.net/forum?id=zl3nFqY8l1) _Submitted to The Thirteenth In-_ _ternational Conference on Learning Representations_ . Under review. HiteshwarKumarAzadandAkshayDeepak.2019. [Query expansion techniques for information retrieval:](https://doi.org/10.1016/J.IPM.2019.05.009) [A survey.](https://doi.org/10.1016/J.IPM.2019.05.009) _Inf. Process. Manag._, 56(5):1698–1735. Ingeol Baek, Jimin Lee, Joonho Yang, and Hwanhee [Lee. 2024. Crafting the path: Robust query rewriting](https://doi.org/10.48550/ARXIV.2407.12529) [for information retrieval.](https://doi.org/10.48550/ARXIV.2407.12529) _CoRR_, abs/2407.12529. Zechen Bai, Tianjun Xiao, Tong He, Pichao Wang, Zheng Zhang, Thomas Brox, and Mike Zheng Shou. [2024. GQE: generalized query expansion for en-](https://doi.org/10.48550/ARXIV.2408.07249) [hanced text-video retrieval.](https://doi.org/10.48550/ARXIV.2408.07249) _CoRR_, abs/2408.07249. Yuzheng Cai, Zhenyue Guo, Yiwen Pei, Wanrui Bian, [and Weiguo Zheng. 2024. Simgrag: Leveraging sim-](https://arxiv.org/abs/2412.15272) [ilar subgraphs for knowledge graphs driven retrieval-](https://arxiv.org/abs/2412.15272) [augmented generation.](https://arxiv.org/abs/2412.15272) _Preprint_, arXiv:2412.15272. Chi-Min Chan, Chunpu Xu, Ruibin Yuan, Hongyin Luo, Wei Xue, Yike Guo, and Jie Fu. 2024. Rq-RAG: Learning to Refine Queries for Retrieval Augmented Generation. _arXiv_, abs/2404.00610. Zhaorun Chen, Zhuokai Zhao, Zhihong Zhu, Ruiqi Zhang, Xiang Li, Bhiksha Raj, and Huaxiu Yao. [2024. Autoprm: Automating procedural supervision](https://doi.org/10.18653/V1/2024.NAACL-LONG.73) [for multi-step reasoning via controllable question de-](https://doi.org/10.18653/V1/2024.NAACL-LONG.73) [composition. In](https://doi.org/10.18653/V1/2024.NAACL-LONG.73) _Proceedings of the 2024 Conference_ _of the North American Chapter of the Association_ _for Computational Linguistics: Human Language_ _Technologies (Volume 1: Long Papers), NAACL 2024,_ _Mexico City, Mexico, June 16-21, 2024_, pages 1346–",
    "metadata": {
      "page_number": 9,
      "header": "References",
      "chunk_index": 17,
      "file_path": "A Survey of Query Optimization in Large Language Models.pdf",
      "token_count": 2534
    }
  },
  {
    "text": "Yung-Sung Chuang, Wei Fang, Shang-Wen Li, Wen-tau [Yih, and James R. Glass. 2023. Expand, rerank, and](https://doi.org/10.18653/V1/2023.FINDINGS-ACL.768) [retrieve: Query reranking for open-domain question](https://doi.org/10.18653/V1/2023.FINDINGS-ACL.768) [answering. In](https://doi.org/10.18653/V1/2023.FINDINGS-ACL.768) _Findings of the Association for Com-_ _putational Linguistics: ACL 2023, Toronto, Canada,_ _July 9-14, 2023_, pages 12131–12147. Association for Computational Linguistics. Youan Cong, Cheng Wang, Pritom Saha Akash, and Kevin Chen-Chuan Chang. 2024. [Query opti-](https://arxiv.org/abs/2411.07820) [mization for parametric knowledge refinement in](https://arxiv.org/abs/2411.07820) [retrieval-augmented large language models.](https://arxiv.org/abs/2411.07820) _Preprint_, arXiv:2411.07820. Zhuyun Dai, Vincent Y. Zhao, Ji Ma, Yi Luan, Jianmo Ni, Jing Lu, Anton Bakalov, Kelvin Guu, Keith B. [Hall, and Ming-Wei Chang. 2023. Promptagator:](https://openreview.net/forum?id=gmL46YMpu2J) [Few-shot dense retrieval from 8 examples. In](https://openreview.net/forum?id=gmL46YMpu2J) _The_ _Eleventh International Conference on Learning Rep-_ _resentations, ICLR 2023, Kigali, Rwanda, May 1-5,_ _2023_ . OpenReview.net. Mohammad Dehghan, Mohammad Ali Alomrani, Sunyam Bagga, David Alfonso-Hermelo, Khalil Bibi, Abbas Ghaddar, Yingxue Zhang, Xiaoguang Li, Jianye Hao, Qun Liu, Jimmy Lin, Boxing Chen, Prasanna Parthasarathi, Mahdi Biparva, and Mehdi [Rezagholizadeh. 2024. EWEK-QA : Enhanced web](https://doi.org/10.18653/V1/2024.ACL-LONG.764) [and efficient knowledge graph retrieval for citation-](https://doi.org/10.18653/V1/2024.ACL-LONG.764) [based question answering systems. In](https://doi.org/10.18653/V1/2024.ACL-LONG.764) _Proceedings_ _of the 62nd Annual Meeting of the Association for_ _Computational Linguistics (Volume 1: Long Papers),_ _ACL2024,Bangkok,Thailand,August11-16,2024_, pages 14169–14187. Association for Computational Linguistics. [Kaustubh D. Dhole and Eugene Agichtein. 2024. Gen-](https://doi.org/10.1007/978-3-031-56063-7_24) [qrensemble: Zero-shot LLM ensemble prompting](https://doi.org/10.1007/978-3-031-56063-7_24) [for generative query reformulation. In](https://doi.org/10.1007/978-3-031-56063-7_24) _Advances in_ _Information Retrieval - 46th European Conference_ _on Information Retrieval, ECIR 2024, Glasgow, UK,_ _March 24-28, 2024, Proceedings, Part III_, volume 14610 of _Lecture Notes in Computer Science_, pages 326–335. Springer. Wenqi Fan, Yujuan Ding, Liangbo Ning, Shijie Wang, Hengyun Li, Dawei Yin, Tat-Seng Chua, and Qing [Li. 2024. A survey on RAG meeting llms: Towards](https://doi.org/10.1145/3637528.3671470) [retrieval-augmented large language models. In](https://doi.org/10.1145/3637528.3671470) _Pro-_ _ceedings of the 30th ACM SIGKDD Conference on_ _Knowledge Discovery and Data Mining, KDD 2024,_ _Barcelona, Spain, August 25-29, 2024_, pages 6491–",
    "metadata": {
      "page_number": 9,
      "header": "1362. Association for Computational Linguistics.",
      "chunk_index": 18,
      "file_path": "A Survey of Query Optimization in Large Language Models.pdf",
      "token_count": 2927
    }
  },
  {
    "text": "Jiazhan Feng, Chongyang Tao, Xiubo Geng, Tao Shen, Can Xu, Guodong Long, Dongyan Zhao, and Daxin [Jiang. 2024. Synergistic interplay between search](https://doi.org/10.18653/V1/2024.ACL-LONG.517) [and large language models for information retrieval.](https://doi.org/10.18653/V1/2024.ACL-LONG.517) In _Proceedings of the 62nd Annual Meeting of the_ _Association for Computational Linguistics (Volume_ _1: Long Papers), ACL 2024, Bangkok, Thailand, Au-_ _gust 11-16, 2024_, pages 9571–9583. Association for Computational Linguistics. Luyu Gao, Xueguang Ma, Jimmy Lin, and Jamie Callan. [2023a. Precise zero-shot dense retrieval without rel-](https://doi.org/10.18653/V1/2023.ACL-LONG.99) [evance labels. In](https://doi.org/10.18653/V1/2023.ACL-LONG.99) _Proceedings of the 61st Annual_ _Meeting of the Association for Computational Lin-_ _guistics (Volume 1: Long Papers), ACL 2023, Toronto,_ _Canada, July 9-14, 2023_, pages 1762–1777. Association for Computational Linguistics. Silin Gao, Jane Dwivedi-Yu, Ping Yu, Xiaoqing Ellen Tan, Ramakanth Pasunuru, Olga Golovneva, Koustuv Sinha, Asli Celikyilmaz, Antoine Bosselut, and [Tianlu Wang. 2024. Efficient tool use with chain-of-](https://arxiv.org/abs/2401.17464) [abstraction reasoning.](https://arxiv.org/abs/2401.17464) _Preprint_, arXiv:2401.17464. Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Qianyu Guo, [Meng Wang, and Haofen Wang. 2023b. Retrieval-](https://doi.org/10.48550/ARXIV.2312.10997) [augmented generation for large language models: A](https://doi.org/10.48550/ARXIV.2312.10997) [survey.](https://doi.org/10.48550/ARXIV.2312.10997) _CoRR_, abs/2312.10997. Shailja Gupta, Rajesh Ranjan, and Surya Narayan Singh. 2024. A [comprehensive](https://doi.org/10.48550/ARXIV.2410.12837) survey of [retrieval-augmented generation (RAG): evolution,](https://doi.org/10.48550/ARXIV.2410.12837) [current landscape and future directions.](https://doi.org/10.48550/ARXIV.2410.12837) _CoRR_, abs/2410.12837. Rujun Han, Yuhao Zhang, Peng Qi, Yumo Xu, Jenyuan Wang, Lan Liu, William Yang Wang, Bonan Min, and [Vittorio Castelli. 2024. RAG-QA arena: Evaluating](https://aclanthology.org/2024.emnlp-main.249) [domain robustness for long-form retrieval augmented](https://aclanthology.org/2024.emnlp-main.249) [question answering. In](https://aclanthology.org/2024.emnlp-main.249) _Proceedings of the 2024 Con-_ _ference on Empirical Methods in Natural Language_ _Processing, EMNLP 2024, Miami, FL, USA, Novem-_ _ber 12-16, 2024_, pages 4354–4374. Association for ComputationalLinguistics. Bolei He, Nuo Chen, Xinran He, Lingyong Yan, Zhenkai Wei, Jinchang Luo, and Zhen-Hua Ling. [2024. Retrieving, rethinking and revising: The chain-](https://arxiv.org/abs/2410.05801) [of-verification can improve retrieval augmented gen-](https://arxiv.org/abs/2410.05801) [eration.](https://arxiv.org/abs/2410.05801) _Preprint_, arXiv:2410.05801. Zijian Hei, Weiling Liu, Wenjie Ou, Juyi Qiao, Junming Jiao, Guowen Song, Ting Tian, and Yi Lin. [2024. Dr-rag: Applying dynamic document rele-](https://arxiv.org/abs/2406.07348) [vance to retrieval-augmented generation for question-](https://arxiv.org/abs/2406.07348) [answering.](https://arxiv.org/abs/2406.07348) _Preprint_, arXiv:2406.07348. Ruixin Hong, Hongming Zhang, Xiaoman Pan, Dong [Yu, and Changshui Zhang. 2024. Abstraction-of-](https://doi.org/10.48550/ARXIV.2406.12442) [thought makes language models better reasoners.](https://doi.org/10.48550/ARXIV.2406.12442) _CoRR_, abs/2406.12442. [Yucheng Hu and Yuxing Lu. 2024. RAG and RAU:](https://doi.org/10.48550/ARXIV.2404.19543) [A survey on retrieval-augmented language model in](https://doi.org/10.48550/ARXIV.2404.19543) [natural language processing.](https://doi.org/10.48550/ARXIV.2404.19543) _CoRR_, abs/2404.19543. [Yizheng Huang and Jimmy Huang. 2024. A survey](https://doi.org/10.48550/ARXIV.2404.10981) [on retrieval-augmented text generation for large lan-](https://doi.org/10.48550/ARXIV.2404.10981) [guage models.](https://doi.org/10.48550/ARXIV.2404.10981) _CoRR_, abs/2404.10981. Rolf Jagerman, Honglei Zhuang, Zhen Qin, Xuanhui [Wang, and Michael Bendersky. 2023. Query expan-](https://doi.org/10.48550/ARXIV.2305.03653) [sion by prompting large language models.](https://doi.org/10.48550/ARXIV.2305.03653) _CoRR_, abs/2305.03653. Pengyue Jia, Yiding Liu, Xiangyu Zhao, Xiaopeng Li, Changying Hao, Shuaiqiang Wang, and Dawei Yin. [2024. MILL: mutual verification with large language](https://doi.org/10.18653/V1/2024.NAACL-LONG.138) [models for zero-shot query expansion. In](https://doi.org/10.18653/V1/2024.NAACL-LONG.138) _Proceed-_ _ings of the 2024 Conference of the North American_ _Chapter of the Association for Computational Lin-_ _guistics: Human Language Technologies (Volume 1:_ _Long Papers), NAACL 2024, Mexico City, Mexico,_ _June 16-21, 2024_, pages 2498–2518. Association for Computational Linguistics. Jinhao Jiang, Jiayi Chen, Junyi Li, Ruiyang Ren, Shijie Wang, Wayne Xin Zhao, Yang Song, and Tao Zhang. [2024. Rag-star: Enhancing deliberative reasoning](https://arxiv.org/abs/2412.12881) [with retrieval augmented verification and refinement.](https://arxiv.org/abs/2412.12881) _Preprint_, arXiv:2412.12881. Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie [Callan, and Graham Neubig. 2023. Active retrieval](https://doi.org/10.18653/V1/2023.EMNLP-MAIN.495) [augmented generation. In](https://doi.org/10.18653/V1/2023.EMNLP-MAIN.495) _Proceedings of the 2023_ _Conference on Empirical Methods in Natural Lan-_ _guage Processing, EMNLP 2023, Singapore, Decem-_ _ber 6-10, 2023_, pages 7969–7992. Association for Computational Linguistics. Ashutosh Joshi, Sheikh Muhammad Sarwar, Samarth Varshney, Sreyashi Nag, Shrivats Agrawal, and Juhi Naik. 2024. [REAPER: reasoning based re-](https://doi.org/10.48550/ARXIV.2407.18553) [trieval planning for complex RAG systems.](https://doi.org/10.48550/ARXIV.2407.18553) _CoRR_, abs/2407.18553. Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric [Wallace, and Colin Raffel. 2023. Large language](https://proceedings.mlr.press/v202/kandpal23a.html) [models struggle to learn long-tail knowledge. In](https://proceedings.mlr.press/v202/kandpal23a.html) _In-_ _ternationalConferenceonMachineLearning,ICML_ _2023, 23-29 July 2023, Honolulu, Hawaii, USA_, volume 202 of _Proceedings of Machine Learning Re-_ _search_, pages 15696–15707. PMLR. Omar Khattab, Keshav Santhanam, Xiang Lisa Li, David Hall, Percy Liang, Christopher Potts, and [Matei Zaharia. 2022. Demonstrate-search-predict:](https://doi.org/10.48550/ARXIV.2212.14024) [Composing retrieval and language models for](https://doi.org/10.48550/ARXIV.2212.14024) [knowledge-intensive NLP.](https://doi.org/10.48550/ARXIV.2212.14024) _CoRR_, abs/2212.14024. Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish Sab[harwal. 2023. Decomposed prompting: A modular](https://openreview.net/forum?id=_nGgzQjzaRy) [approach for solving complex tasks. In](https://openreview.net/forum?id=_nGgzQjzaRy) _The Eleventh_ _International Conference on Learning Representa-_ _tions, ICLR 2023, Kigali, Rwanda, May 1-5, 2023_ . OpenReview.net. Gangwoo Kim, Sungdong Kim, Byeongguk Jeon, Joon[suk Park, and Jaewoo Kang. 2023. Tree of clarifica-](https://doi.org/10.18653/V1/2023.EMNLP-MAIN.63) [tions: Answering ambiguous questions with retrieval-](https://doi.org/10.18653/V1/2023.EMNLP-MAIN.63) [augmented large language models. In](https://doi.org/10.18653/V1/2023.EMNLP-MAIN.63) _Proceedings of_ _the 2023 Conference on Empirical Methods in Natu-_ _ral Language Processing, EMNLP 2023, Singapore,_ _December 6-10, 2023_, pages 996–1009. Association for Computational Linguistics. Anton Korikov, George Saad, Ethan Baron, Mustafa [Khan, Manav Shah, and Scott Sanner. 2024. Multi-](https://doi.org/10.48550/ARXIV.2408.00878) [aspect reviewed-item retrieval via LLM query decom-](https://doi.org/10.48550/ARXIV.2408.00878) [position and aspect fusion.](https://doi.org/10.48550/ARXIV.2408.00878) _CoRR_, abs/2408.00878. Tzu-Lin Kuo, Feng-Ting Liao, Mu-Wei Hsieh, FuChieh Chang, Po-Chun Hsu, and Da-Shan Shiu. 2024. [Rad-bench: Evaluating large language models ca-](https://doi.org/10.48550/ARXIV.2409.12558) [pabilities in retrieval augmented dialogues.](https://doi.org/10.48550/ARXIV.2409.12558) _CoRR_, abs/2409.12558. Yibin Lei, Yu Cao, Tianyi Zhou, Tao Shen, and Andrew [Yates. 2024. Corpus-steered query expansion with](https://aclanthology.org/2024.eacl-short.34) [large language models. In](https://aclanthology.org/2024.eacl-short.34) _Proceedings of the 18th_ _Conference of the European Chapter of the Associ-_ _ation for Computational Linguistics, EACL 2024 -_ _Volume 2: Short Papers, St. Julian’s, Malta, March_ _17-22, 2024_, pages 393–401. Association for Computational Linguistics. Patrick S. H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2020. [Retrieval-augmented gener-](https://arxiv.org/abs/2005.11401) [ation for knowledge-intensive NLP tasks.](https://arxiv.org/abs/2005.11401) _CoRR_, abs/2005.11401. Xingxuan Li, Ruochen Zhao, Yew Ken Chia, Bosheng Ding, Shafiq Joty, Soujanya Poria, and Lidong Bing. [2024. Chain-of-knowledge: Grounding large lan-](https://openreview.net/forum?id=cPgh4gWZlz) [guage models via dynamic knowledge adapting over](https://openreview.net/forum?id=cPgh4gWZlz) [heterogeneous sources. In](https://openreview.net/forum?id=cPgh4gWZlz) _The Twelfth International_ _Conference on Learning Representations, ICLR 2024,_ _Vienna, Austria, May 7-11, 2024_ . OpenReview.net. Zhan Ling, Yunhao Fang, Xuanlin Li, Zhiao Huang, MinguLee,RolandMemisevic,andHaoSu.2023. [Deductive verification of chain-of-thought reason-](http://papers.nips.cc/paper_files/paper/2023/hash/72393bd47a35f5b3bee4c609e7bba733-Abstract-Conference.html) [ing. In](http://papers.nips.cc/paper_files/paper/2023/hash/72393bd47a35f5b3bee4c609e7bba733-Abstract-Conference.html) _Advances in Neural Information Processing_ _Systems 36: Annual Conference on Neural Informa-_ _tion Processing Systems 2023, NeurIPS 2023, New_ _Orleans, LA, USA, December 10 - 16, 2023_ . Yanming Liu, Xinyue Peng, Xuhong Zhang, Weihao Liu, Jianwei Yin, Jiannan Cao, and Tianyu Du. 2024. [RA-ISF: learning to answer and understand from re-](https://doi.org/10.18653/V1/2024.FINDINGS-ACL.281) [trieval augmentation via iterative self-feedback. In](https://doi.org/10.18653/V1/2024.FINDINGS-ACL.281) _Findings of the Association for Computational Lin-_ _guistics, ACL 2024, Bangkok, Thailand and virtual_ _meeting, August 11-16, 2024_, pages 4730–4749. Association for Computational Linguistics. Qianli Ma, Haotian Zhou, Tingkai Liu, Jianbo Yuan, Pengfei Liu, Yang You, and Hongxia Yang. 2023a. [Let’s reward step by step: Step-level reward model as](https://doi.org/10.48550/ARXIV.2310.10080) [the navigators for reasoning.](https://doi.org/10.48550/ARXIV.2310.10080) _CoRR_, abs/2310.10080. Xinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao, and Nan Duan. 2023b. [Query rewriting for](https://doi.org/10.48550/ARXIV.2305.14283) [retrieval-augmented large language models.](https://doi.org/10.48550/ARXIV.2305.14283) _CoRR_, abs/2305.14283. Shengyu Mao, Yong Jiang, Boli Chen, Xiao Li, Peng Wang, Xinyu Wang, Pengjun Xie, Fei Huang, Huajun Chen, and Ningyu Zhang. 2024. [Rafe: Ranking](https://doi.org/10.48550/ARXIV.2405.14431) [feedback improves query rewriting for RAG.](https://doi.org/10.48550/ARXIV.2405.14431) _CoRR_, abs/2405.14431. Raja Sekhar Reddy Mekala, Yasaman Razeghi, and [Sameer Singh. 2024. Echoprompt: Instructing the](https://doi.org/10.18653/V1/2024.NAACL-SHORT.35) [model to rephrase queries for improved in-context](https://doi.org/10.18653/V1/2024.NAACL-SHORT.35) [learning. In](https://doi.org/10.18653/V1/2024.NAACL-SHORT.35) _Proceedings of the 2024 Conference of_ _the North American Chapter of the Association for_ _Computational Linguistics: Human Language Tech-_ _nologies: Short Papers, NAACL 2024, Mexico City,_ _Mexico, June 16-21, 2024_, pages 399–432. Association for Computational Linguistics. Fengran Mo, Abbas Ghaddar, Kelong Mao, Mehdi Rezagholizadeh, Boxing Chen, Qun Liu, and Jian-Yun Nie. [2024. CHIQ: contextual history enhancement for](https://doi.org/10.48550/ARXIV.2406.05013) [improving query rewriting in conversational search.](https://doi.org/10.48550/ARXIV.2406.05013) _CoRR_, abs/2406.05013. [Jeonghyun Park and Hwanhee Lee. 2024. Conversa-](https://doi.org/10.48550/ARXIV.2407.12363) [tional query reformulation with the guidance of re-](https://doi.org/10.48550/ARXIV.2407.12363) [trieved documents.](https://doi.org/10.48550/ARXIV.2407.12363) _CoRR_, abs/2407.12363. Boci Peng, Yun Zhu, Yongchao Liu, Xiaohe Bo, Haizhou Shi, Chuntao Hong, Yan Zhang, and Siliang [Tang. 2024a. Graph retrieval-augmented generation:](https://doi.org/10.48550/ARXIV.2408.08921) [A survey.](https://doi.org/10.48550/ARXIV.2408.08921) _CoRR_, abs/2408.08921. Wenjun Peng, Guiyang Li, Yue Jiang, Zilong Wang, Dan Ou, Xiaoyi Zeng, Derong Xu, Tong Xu, and Enhong [Chen. 2024b. Large language model based long-](https://doi.org/10.1145/3589335.3648298) [tail query rewriting in taobao search. In](https://doi.org/10.1145/3589335.3648298) _Companion_ _Proceedings of the ACM on Web Conference 2024,_ _WWW 2024, Singapore, Singapore, May 13-17, 2024_, pages 20–28. ACM. Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, NoahA.Smith,andMikeLewis.2023. [Measuring](https://doi.org/10.18653/V1/2023.FINDINGS-EMNLP.378) [and narrowing the compositionality gap in language](https://doi.org/10.18653/V1/2023.FINDINGS-EMNLP.378) [models. In](https://doi.org/10.18653/V1/2023.FINDINGS-EMNLP.378) _Findings of the Association for Compu-_ _tational Linguistics: EMNLP 2023, Singapore, De-_ _cember 6-10, 2023_, pages 5687–5711. Association for Computational Linguistics. Zhenting Qi, Mingyuan Ma, Jiahang Xu, Li Lyna Zhang, [Fan Yang, and Mao Yang. 2024. Mutual reasoning](https://doi.org/10.48550/ARXIV.2408.06195) [makes smaller llms stronger problem-solvers.](https://doi.org/10.48550/ARXIV.2408.06195) _CoRR_, abs/2408.06195. Kashob Kumar Roy, Pritom Saha Akash, Kevin ChenChuan Chang, and Lucian Popa. 2024. [Contre-](https://arxiv.org/abs/2410.15511) gen: [Context-driven tree-structured retrieval for](https://arxiv.org/abs/2410.15511) [open-domain long-form text generation.](https://arxiv.org/abs/2410.15511) _Preprint_, arXiv:2410.15511. Amrith Setlur, Chirag Nagpal, Adam Fisch, Xinyang Geng, Jacob Eisenstein, Rishabh Agarwal, Alekh Agarwal, Jonathan Berant, and Aviral Kumar. 2024. [Rewarding progress: Scaling automated process veri-](https://doi.org/10.48550/ARXIV.2410.08146) [fiers for LLM reasoning.](https://doi.org/10.48550/ARXIV.2410.08146) _CoRR_, abs/2410.08146. Tao Shen, Guodong Long, Xiubo Geng, Chongyang Tao, Yibin Lei, Tianyi Zhou, Michael Blumenstein, and [Daxin Jiang. 2024a. Retrieval-augmented retrieval:](https://doi.org/10.18653/V1/2024.FINDINGS-ACL.943) [Large language models are strong zero-shot retriever.](https://doi.org/10.18653/V1/2024.FINDINGS-ACL.943) In _Findings of the Association for Computational Lin-_ _guistics, ACL 2024, Bangkok, Thailand and virtual_ _meeting, August 11-16, 2024_, pages 15933–15946. Association for Computational Linguistics. Yige Shen, Hao Jiang, Hua Qu, and Jihong Zhao. 2024b. [Think-then-act: A dual-angle evaluated retrieval-](https://doi.org/10.48550/ARXIV.2406.13050) [augmented generation.](https://doi.org/10.48550/ARXIV.2406.13050) _CoRR_, abs/2406.13050. Weihang Su, Yichen Tang, Qingyao Ai, Zhijing Wu, [and Yiqun Liu. 2024. DRAGIN: dynamic retrieval](https://doi.org/10.18653/V1/2024.ACL-LONG.702) [augmented generation based on the real-time informa-](https://doi.org/10.18653/V1/2024.ACL-LONG.702) [tion needs of large language models. In](https://doi.org/10.18653/V1/2024.ACL-LONG.702) _Proceedings_ _of the 62nd Annual Meeting of the Association for_ _Computational Linguistics (Volume 1: Long Papers),_ _ACL 2024, Bangkok, Thailand, August 11-16, 2024_, pages 12991–13013. Association for Computational Linguistics. S. M. Towhidul Islam Tonmoy, S. M. Mehedi Zaman, Vinija Jain, Anku Rani, Vipula Rawte, Aman Chadha, [and Amitava Das. 2024. A comprehensive survey of](https://doi.org/10.48550/ARXIV.2401.01313) [hallucination mitigation techniques in large language](https://doi.org/10.48550/ARXIV.2401.01313) [models.](https://doi.org/10.48550/ARXIV.2401.01313) _CoRR_, abs/2401.01313. Venktesh V, Sourangshu Bhattacharya, and Avishek Anand. 2023. [In-context ability transfer for](https://doi.org/10.48550/ARXIV.2310.18371) [question decomposition in complex QA.](https://doi.org/10.48550/ARXIV.2310.18371) _CoRR_, abs/2310.18371. Prakhar Verma, Sukruta Prakash Midigeshi, Gaurav Sinha, Arno Solin, Nagarajan Natarajan, and Amit Sharma. 2024. Plan _×_ [rag: Planning-guided retrieval](https://arxiv.org/abs/2410.20753) [augmented generation.](https://arxiv.org/abs/2410.20753) _Preprint_, arXiv:2410.20753. Sourav Verma. 2024. [Contextual compression in](https://doi.org/10.48550/ARXIV.2409.13385) [retrieval-augmented generation for large language](https://doi.org/10.48550/ARXIV.2409.13385) [models:Asurvey.](https://doi.org/10.48550/ARXIV.2409.13385) _CoRR_,abs/2409.13385. [Haoyu Wang, Tuo Zhao, and Jing Gao. 2024a. Blendfil-](https://doi.org/10.48550/ARXIV.2402.11129) [ter: Advancing retrieval-augmented large language](https://doi.org/10.48550/ARXIV.2402.11129) [models via query generation blending and knowledge](https://doi.org/10.48550/ARXIV.2402.11129) [filtering.](https://doi.org/10.48550/ARXIV.2402.11129) _CoRR_, abs/2402.11129. Junjie Wang, Mingyang Chen, Binbin Hu, Dan Yang, Ziqi Liu, Yue Shen, Peng Wei, Zhiqiang Zhang, Jinjie Gu, Jun Zhou, Jeff Z. Pan, Wen Zhang, and Huajun Chen. 2024b. [Learning to plan for retrieval-](https://doi.org/10.48550/ARXIV.2406.14282) [augmented large language models from knowledge](https://doi.org/10.48550/ARXIV.2406.14282) [graphs.](https://doi.org/10.48550/ARXIV.2406.14282) _CoRR_, abs/2406.14282. Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, and Ee-Peng Lim. [2023a. Plan-and-solve prompting: Improving zero-](https://doi.org/10.18653/V1/2023.ACL-LONG.147) [shot chain-of-thought reasoning by large language](https://doi.org/10.18653/V1/2023.ACL-LONG.147) [models. In](https://doi.org/10.18653/V1/2023.ACL-LONG.147) _Proceedings of the 61st Annual Meeting_ _of the Association for Computational Linguistics (Vol-_ _ume 1: Long Papers), ACL 2023, Toronto, Canada,_ _July 9-14, 2023_, pages 2609–2634. Association for Computational Linguistics. Liang Wang, Nan Yang, and Furu Wei. 2023b. [Query2doc: Query expansion with large language](https://doi.org/10.18653/V1/2023.EMNLP-MAIN.585) [models. In](https://doi.org/10.18653/V1/2023.EMNLP-MAIN.585) _Proceedings of the 2023 Conference on_ _Empirical Methods in Natural Language Process-_ _ing, EMNLP 2023, Singapore, December 6-10, 2023_, pages 9414–9423. Association for Computational Linguistics. Shuting Wang, Xin Yu, Mang Wang, Weipeng Chen, Yutao Zhu, and Zhicheng Dou. 2024c. [Richrag: Crafting rich responses for multi-faceted](https://doi.org/10.48550/ARXIV.2406.12566) [queries in retrieval-augmented generation.](https://doi.org/10.48550/ARXIV.2406.12566) _CoRR_, abs/2406.12566. Xintao Wang, Qianwen Yang, Yongting Qiu, Jiaqing Liang, Qianyu He, Zhouhong Gu, Yanghua Xiao, and [Wei Wang. 2023c. Knowledgpt: Enhancing large](https://doi.org/10.48550/ARXIV.2308.11761) [language models with retrieval and storage access on](https://doi.org/10.48550/ARXIV.2308.11761) [knowledge bases.](https://doi.org/10.48550/ARXIV.2308.11761) _CoRR_, abs/2308.11761. Yiming Wang, Zhuosheng Zhang, Pei Zhang, Baosong Yang, and Rui Wang. 2024d. [Meta-reasoning:](https://doi.org/10.18653/V1/2024.FINDINGS-ACL.34) [Semantics-symbol deconstruction for large language](https://doi.org/10.18653/V1/2024.FINDINGS-ACL.34) [models. In](https://doi.org/10.18653/V1/2024.FINDINGS-ACL.34) _Findings of the Association for Computa-_ _tional Linguistics, ACL 2024, Bangkok, Thailand and_ _virtual meeting, August 11-16, 2024_, pages 622–643. Association for Computational Linguistics. Yujing Wang, Hainan Zhang, Liang Pang, Binghui Guo, Hongwei Zheng, and Zhiming Zheng. 2024e. [Maferw: Query rewriting with multi-aspect feed-](https://doi.org/10.48550/ARXIV.2408.17072) [backs for retrieval-augmented large language models.](https://doi.org/10.48550/ARXIV.2408.17072) _CoRR_, abs/2408.17072. Zhaowei Wang, Wei Fan, Qing Zong, Hongming Zhang, Sehyun Choi, Tianqing Fang, Xin Liu, Yangqiu Song, [Ginny Y. Wong, and Simon See. 2024f. Absinstruct:](https://doi.org/10.18653/V1/2024.ACL-LONG.55) [Eliciting abstraction ability from llms through expla-](https://doi.org/10.18653/V1/2024.ACL-LONG.55) [nation tuning with plausibility estimation. In](https://doi.org/10.18653/V1/2024.ACL-LONG.55) _Pro-_ _ceedings of the 62nd Annual Meeting of the Associa-_ _tion for Computational Linguistics (Volume 1: Long_ _Papers), ACL 2024, Bangkok, Thailand, August 11-_ _16, 2024_, pages 973–994. Association for ComputationalLinguistics. Zhaowei Wang, Haochen Shi, Weiqi Wang, Tianqing Fang, Hongming Zhang, Sehyun Choi, Xin Liu, and [Yangqiu Song. 2024g. Abspyramid: Benchmarking](https://doi.org/10.18653/V1/2024.FINDINGS-NAACL.252) [the abstraction ability of language models with a uni-](https://doi.org/10.18653/V1/2024.FINDINGS-NAACL.252) [fied entailment graph. In](https://doi.org/10.18653/V1/2024.FINDINGS-NAACL.252) _Findings of the Association_ _for Computational Linguistics: NAACL 2024, Mexico_ _City, Mexico, June 16-21, 2024_, pages 3991–4010. Association for Computational Linguistics. Orion Weller, Kyle Lo, David Wadden, Dawn J. Lawrie, Benjamin Van Durme, Arman Cohan, and Luca Sol[daini. 2024. When do generative query and docu-](https://aclanthology.org/2024.findings-eacl.134) [ment expansions fail? A comprehensive study across](https://aclanthology.org/2024.findings-eacl.134) [methods, retrievers, and datasets. In](https://aclanthology.org/2024.findings-eacl.134) _Findings of the_ _Association for Computational Linguistics: EACL_ _2024, St. Julian’s, Malta, March 17-22, 2024_, pages 1987–2003. Association for Computational Linguistics. Shangyu Wu, Ying Xiong, Yufei Cui, Haolun Wu, Can Chen, Ye Yuan, Lianming Huang, Xue Liu, TeiWei Kuo, Nan Guan, and Chun Jason Xue. 2024. [Retrieval-augmented generation for natural language](https://doi.org/10.48550/ARXIV.2407.13193) [processing: A survey.](https://doi.org/10.48550/ARXIV.2407.13193) _CoRR_, abs/2407.13193. Kaige Xie, Philippe Laban, Prafulla Kumar Choubey, [Caiming Xiong, and Chien-Sheng Wu. 2024. Do](https://doi.org/10.48550/ARXIV.2410.15531) [RAG systems cover what matters? evaluating and](https://doi.org/10.48550/ARXIV.2410.15531) [optimizing responses with sub-question coverage.](https://doi.org/10.48550/ARXIV.2410.15531) _CoRR_, abs/2410.15531. Diji Yang, Jinmeng Rao, Kezhen Chen, Xiaoyuan Guo, [Yawen Zhang, Jie Yang, and Yi Zhang. 2024. IM-](https://doi.org/10.1145/3626772.3657760) [RAG: multi-round retrieval-augmented generation](https://doi.org/10.1145/3626772.3657760) [through learning inner monologues. In](https://doi.org/10.1145/3626772.3657760) _Proceedings_ _of the 47th International ACM SIGIR Conference on_ _Research and Development in Information Retrieval,_ _SIGIR 2024, Washington DC, USA, July 14-18, 2024_, pages 730–740. ACM. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R. Narasimhan, and Yuan Cao. 2023. [React: Synergizing reasoning and acting in language](https://openreview.net/forum?id=WE_vluYUL-X) [models. In](https://openreview.net/forum?id=WE_vluYUL-X) _The Eleventh International Conference_ _on Learning Representations, ICLR 2023, Kigali,_ _Rwanda, May 1-5, 2023_ . OpenReview.net. Fanghua Ye, Meng Fang, Shenghui Li, and Emine Yil[maz. 2023. Enhancing conversational search: Large](https://doi.org/10.18653/V1/2023.FINDINGS-EMNLP.398) [language model-aided informative query rewriting.](https://doi.org/10.18653/V1/2023.FINDINGS-EMNLP.398) In _Findings of the Association for Computational Lin-_ _guistics: EMNLP 2023, Singapore, December 6-10,_ _2023_, pages 5985–6006. Association for Computational Linguistics. Wenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu, Mingxuan Ju, Soumya Sanyal, Chenguang Zhu, [Michael Zeng, and Meng Jiang. 2023a. Generate](https://openreview.net/forum?id=fB0hRu9GZUS) [rather than retrieve: Large language models are](https://openreview.net/forum?id=fB0hRu9GZUS) [strong context generators. In](https://openreview.net/forum?id=fB0hRu9GZUS) _The Eleventh Inter-_ _national Conference on Learning Representations,_ _ICLR 2023, Kigali, Rwanda, May 1-5, 2023_ . OpenReview.net. Wenhao Yu, Zhihan Zhang, Zhenwen Liang, Meng [Jiang, and Ashish Sabharwal. 2023b. Improving lan-](https://arxiv.org/abs/2305.14002) [guage models via plug-and-play retrieval feedback.](https://arxiv.org/abs/2305.14002) _Preprint_, arXiv:2305.14002. Zhenrui Yue, Huimin Zeng, Yimeng Lu, Lanyu Shang, [Yang Zhang, and Dong Wang. 2024. Evidence-driven](https://doi.org/10.18653/V1/2024.NAACL-LONG.313) [retrieval augmented response generation for online](https://doi.org/10.18653/V1/2024.NAACL-LONG.313) [misinformation. In](https://doi.org/10.18653/V1/2024.NAACL-LONG.313) _Proceedings of the 2024 Con-_ _ference of the North American Chapter of the As-_ _sociation for Computational Linguistics: Human_ _Language Technologies (Volume 1: Long Papers),_ _NAACL 2024, Mexico City, Mexico, June 16-21, 2024_, pages 5628–5643. Association for Computational Linguistics. [Han Zhang, Yuheng Ma, and Hanfang Yang. 2024a. AL-](https://doi.org/10.48550/ARXIV.2407.03061) [TER: augmentation for large-table-based reasoning.](https://doi.org/10.48550/ARXIV.2407.03061) _CoRR_, abs/2407.03061. Le Zhang, Yihong Wu, Qian Yang, and Jian-Yun [Nie. 2024b. Exploring the best practices of query](https://arxiv.org/abs/2401.06311) [expansion with large language models.](https://arxiv.org/abs/2401.06311) _Preprint_, arXiv:2401.06311. Tianhua Zhang, Kun Li, Hongyin Luo, Xixin Wu, [James R. Glass, and Helen Meng. 2024c. Adaptive](https://doi.org/10.48550/ARXIV.2406.10991) [query rewriting: Aligning rewriters through marginal](https://doi.org/10.48550/ARXIV.2406.10991) [probability of conversational answers.](https://doi.org/10.48550/ARXIV.2406.10991) _CoRR_, abs/2406.10991. Xiaoming Zhang, Ming Wang, Xiaocui Yang, Daling [Wang, Shi Feng, and Yifei Zhang. 2024d. Hierar-](https://arxiv.org/abs/2408.11875) [chical retrieval-augmented generation model with](https://arxiv.org/abs/2408.11875) [rethink for multi-hop question answering.](https://arxiv.org/abs/2408.11875) _Preprint_, arXiv:2408.11875. Yanan Zhang, Weijie Cui, Yangfan Zhang, Xiaoling Bai, Zhe Zhang, Jin Ma, Xiang Chen, and Tianhua Zhou. [2023a. Event-centric query expansion in web search.](https://doi.org/10.18653/V1/2023.ACL-INDUSTRY.45) In _Proceedings of the The 61st Annual Meeting of_ _the Association for Computational Linguistics: In-_ _dustry Track, ACL 2023, Toronto, Canada, July 9-14,_ _2023_, pages 464–475. Association for Computational Linguistics. Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, Longyue Wang, Anh Tuan Luu, Wei [Bi, Freda Shi, and Shuming Shi. 2023b. Siren’s song](https://doi.org/10.48550/ARXIV.2309.01219) [in the AI ocean: A survey on hallucination in large](https://doi.org/10.48550/ARXIV.2309.01219) [language models.](https://doi.org/10.48550/ARXIV.2309.01219) _CoRR_, abs/2309.01219. Siyun Zhao, Yuqing Yang, Zilong Wang, Zhiyuan He, [Luna Qiu, and Lili Qiu. 2024. Retrieval augmented](https://doi.org/10.48550/ARXIV.2409.14924) [generation (RAG) and beyond: A comprehensive](https://doi.org/10.48550/ARXIV.2409.14924) [survey on how to make your llms use external data](https://doi.org/10.48550/ARXIV.2409.14924) [more wisely.](https://doi.org/10.48550/ARXIV.2409.14924) _CoRR_, abs/2409.14924. Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. [2023. A survey of large language models.](https://doi.org/10.48550/ARXIV.2303.18223) _CoRR_, abs/2303.18223. Huaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen, Heng-Tze Cheng, Ed H. Chi, Quoc V Le, and Denny Zhou. 2024. Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models. In _The Twelfth International Conference on Learning_ _Representations_, volume abs/2310.06117. Ben Zhou, Hongming Zhang, Sihao Chen, Dian Yu, Hongwei Wang, Baolin Peng, Dan Roth, and Dong [Yu. 2024. Conceptual and unbiased reasoning in](https://doi.org/10.48550/ARXIV.2404.00205) [language models.](https://doi.org/10.48550/ARXIV.2404.00205) _CoRR_, abs/2404.00205. Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V. Le, and Ed H. [Chi. 2023. Least-to-most prompting enables com-](https://openreview.net/forum?id=WZH7099tgfM) [plex reasoning in large language models. In](https://openreview.net/forum?id=WZH7099tgfM) _The_ _Eleventh International Conference on Learning Rep-_ _resentations, ICLR 2023, Kigali, Rwanda, May 1-5,_ _2023_ . OpenReview.net. Wang Zhu, Jesse Thomason, and Robin Jia. 2023a. [Chain-of-questions training with latent answers for](https://doi.org/10.18653/V1/2023.EMNLP-MAIN.547) [robust multistep question answering. In](https://doi.org/10.18653/V1/2023.EMNLP-MAIN.547) _Proceedings_ _of the 2023 Conference on Empirical Methods in Nat-_ _ural Language Processing, EMNLP 2023, Singapore,_ _December 6-10, 2023_, pages 8845–8860. Association for Computational Linguistics. Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng, Zhicheng Dou, and Ji[Rong Wen. 2023b. Large language models for infor-](https://doi.org/10.48550/ARXIV.2308.07107) [mation retrieval: A survey.](https://doi.org/10.48550/ARXIV.2308.07107) _CoRR_, abs/2308.07107.",
    "metadata": {
      "page_number": 9,
      "header": "6501. ACM.",
      "chunk_index": 19,
      "file_path": "A Survey of Query Optimization in Large Language Models.pdf",
      "token_count": 30293
    }
  }
]