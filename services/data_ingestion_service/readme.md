# Data Ingestion Service

This service ingests PDF and PPTX documents from a specified Google Drive folder, performs semantic chunking, embeds the content using a language model, and stores the embeddings in ChromaDB. It includes a Streamlit UI for monitoring file ingestion status.

---

## üöÄ Features

* ‚úÖ Google Drive integration (via Service Account)
* ‚úÖ Semantic chunking using LlamaIndex
* ‚úÖ Embedding with `all-MiniLM-L6-v2`
* ‚úÖ Storage in **ChromaDB**
* ‚úÖ Tracking of already processed files
* ‚úÖ Friendly **Streamlit UI** for upload monitoring

---

## üìÇ Project Structure (key parts)

project-root/
‚îÇ
‚îú‚îÄ‚îÄ main.py                               ‚Üê Entry point
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ routes.py                     ‚Üê FastAPI route definitions
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.py                     ‚Üê Env loading, settings
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ schemas/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models.py                     ‚Üê Pydantic models (requests/responses)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ drive_ingestion.py           ‚Üê Main ingestion logic
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ ui/
‚îÇ       ‚îî‚îÄ‚îÄ app.py                        ‚Üê Streamlit UI for monitoring
‚îú‚îÄ‚îÄ secrets/
‚îÇ   ‚îî‚îÄ‚îÄ promising-keep-416609-4d97f7c36ae1.json  ‚Üê üîí Service account (not committed)
‚îî‚îÄ‚îÄ ingestion_state/
    ‚îî‚îÄ‚îÄ KB_processed_files_history.txt   ‚Üê Processed files tracker


---

## ‚öôÔ∏è Environment Variables

Create a `.env` file in the root of your project and define the following:

```env
# Path to your Google Service Account JSON (not committed to repo)
GOOGLE_SERVICE_ACCOUNT_FILE="services/data_ingestion_service/secrets/promising-keep-416609-4d97f7c36ae1.json"

# Path to the tracker file that keeps track of processed files
KB_PROCESSED_FILES="services/data_ingestion_service/ingestion_state/KB_processed_files_history.txt"

# Google Drive folder ID from which files will be fetched
KB_DATA_STORAGE_DRIVE_ID=" " #secret
```

> ‚ö†Ô∏è Do **NOT** commit the `.json` service account file to source control.

---

## üß† Dependencies

Install required libraries:

```bash
pip install -r requirements.txt
```


## ‚ñ∂Ô∏è Running the Ingestion

### 1. Run from CLI

```bash
uvicorn services.data_ingestion_service.src.main:app --loop asyncio --reload
```

This will:

* Connect to the Google Drive folder
* Download `.pdf` and `.pptx` files
* Chunk and embed them
* Persist in Chroma
* Track what‚Äôs been processed

### 2. Run Streamlit UI 

```bash
streamlit run services/data_ingestion_service/ui/app.py
```

* See file upload status
* Preview processed file logs
* Trigger ingestion (optional interactive interface)

---

## üìé Notes

* The ingestion process skips already processed files unless forced.
* Temporary files are auto-deleted after processing.
* Logs are printed via Python‚Äôs `logging` module.
* Chroma DB persists embeddings locally under the specified directory

---
