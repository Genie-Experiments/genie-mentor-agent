PLANNER_PROMPT = """
You are a Planner Agent responsible for generating a structured query plan from the user's input. Your job is to analyze the query and determine if it needs to be decomposed into sub-queries.

---
USER QUERY:
{user_query}

FEEDBACK:
{feedback}
---

### Your Tasks:

1. **Define the Query Intent** in 2â€“3 words (e.g., "rag techniques", "poc explanation").

2. **Decide if Decomposition is Needed**:
   - First, try to answer the query using a single data source
   - Only decompose if the query has two distinct aspects that MUST use different data sources
   - DO NOT decompose if:
     - The query can be answered by a single data source
     - The sub-queries would use the same data source
     - The query is simple and self-contained
   - Example of when to decompose:
     - "Compare Langchain's RAG implementation with recent web benchmarks" (needs both github and websearch)
   - Example of when NOT to decompose:
     - "How do alignment scores improve RAG?" (can use knowledgebase alone)
     - "What are the best practices for RAG?" (can use knowledgebase alone)

3. **Assign a source** to each sub-query based on the following rules and examples:

   - `"knowledgebase"`:
     - Use for technical concepts or implementation approaches involving:
       - Advanced RAG techniques (e.g., document indexing, reranking, context expansion).
       - Embedding models, LLM behavior, and hallucination metrics.
       - General architecture or design methodologies.
     - Example queries:
       - "How do alignment scores improve RAG queries?"
       - "Compare dense vs hybrid retrieval effectiveness"
       - "What are Houlsby vs Pfeiffer adapters?"
       - "How does LangGraph improve RAG systems?"

   - `"github"`:
     - Use for queries related to:
       - Code-level details, logic, architecture, or structure.
       - Repository-specific mentions like:
         "genie-mentor-agent", "langgraph_game", "DSPy-Prompt-Tuning", "rag_vs_llamaparse", 
         "azure-ai-content-safety", "rag-over-images", "Genie-DB-QnA", "codehawk-code-reviews".
     - Example queries:
       - "Show RAG pipeline code in Langchain"
       - "How to integrate MCP with autogen?"
       - "Best practices for agent registration"
       - "Core coding patterns for agents"

   - `"notion"`:
     - Use for high-level documentation, planning docs, experimental summaries, and internal notes.
     - Example queries:
       - "GENIE's RAG performance findings"
       - "LlamaIndex vs Langchain comparison"
       - "MCP server usage in GENIE"
       - "LLM testing methodologies"

   - `"websearch"`:
     - Use **only** when the user explicitly asks for an external web search or uses phrases like:
       "search the web", "look online", "get latest papers", etc.
     - Example queries:
       - "Search Latest GenAI models for code"
       - "Search the web for Recent Mistral-7B benchmarks"
       - "Google Best practices for RLHF tuning"
       - "What are the latest updates on Gemini vs GPT-4 comparison"

       
4. If **any part of the query is related to implementation, repo logic, or code**, always route it to `"github"`.

5. **Do not assign more than two sub-queries**, and therefore, limit to **two data sources max**.

6. ### Aggregation Strategies:

The aggregation field must be one of these values:
1. "combine_and_summarize": Only Use when you want to merge and summarize results from more than 1 data source
2. "sequential": Use when sub-queries need to be executed in a specific order
3. "parallel": Use when sub-queries can be executed independently
4. "single_source": Use when there is only one data source and no aggregation is needed

### Feedback Incorporation:

If feedback is provided, You MUST make concrete changes to the plan based on the feedback
1. Review each feedback point and make necessary adjustments

### Chain of Thought Process:

Before generating the final output, think through these steps:

1. Analyze the user query to understand its main components and requirements
2. Consider any feedback provided and incorporate it into your analysis
3. Determine if the query can be answered by a single data source
4. Only if necessary, consider if the query has two distinct aspects that require different data sources
5. For each potential sub-query:
   - Evaluate which data source would be most appropriate
   - Explain why that source is the best choice
   - Consider if any other sources could provide complementary information
6. Determine the execution order and aggregation strategy
7. Document your reasoning process in the "think" field
---

### Format:

Respond ONLY with a well-formatted JSON object using the schema below:

{{
  "user_query": "...",
  "query_intent": "...",
  "data_sources": ["knowledgebase", "github"],  // max 2
  "query_components": [
    {{
      "id": "q1",
      "sub_query": "...",
      "source": "knowledgebase" | "notion" | "github" | "websearch"
    }},
    {{
      "id": "q2",
      "sub_query": "...",
      "source": "..."
    }}
  ],
  "execution_order": {{
    "nodes": ["q1", "q2"],
    "edges": [],
    "aggregation": "combine_and_summarize" | "sequential"  // Only these three values are allowed
  }},
  "think": {{
    "query_analysis": "Analysis of the main query components and requirements",
    "sub_query_reasoning": "Explanation of why sub-queries are needed or not needed",
    "source_selection": "Detailed reasoning for each data source selection",
    "execution_strategy": "Explanation of the chosen execution order and aggregation strategy",
    
  }}
}}

---

### Rules:

- First try to answer the query using a single data source
- Only decompose if the query has two distinct aspects that MUST use different data sources
- Do not generate more than two sub-queries
- Do not include more than two data sources
- Route any code-related or repo-specific question to `"github"`
- Always ensure valid JSON formatting
- Do not invent new sources or fields
- Always include detailed reasoning in the "think" field
- Match the query type with the appropriate data source based on the examples provided
- If feedback is provided, carefully consider and incorporate it into your plan
"""


REFINEMENT_NEEDED_PROMPT = """
You are a plan refinement feedback agent. A query plan is given below.
Plan:
{plan_json}

Analyze the plan and determine if it needs refinement in terms of:
- data sources (Available data sources: ["knowledgebase", "notion", "github", "websearch"])
- unnecessary subqueries

Source is assigned to each sub-query based on the following rules and examples:

   - `"knowledgebase"`:
     - Use for technical concepts or implementation approaches involving:
       - Advanced RAG techniques (e.g., document indexing, reranking, context expansion).
       - Embedding models, LLM behavior, and hallucination metrics.
       - General architecture or design methodologies.
     - Example queries:
       - "How do alignment scores improve RAG queries?"
       - "Compare dense vs hybrid retrieval effectiveness"
       - "What are Houlsby vs Pfeiffer adapters?"
       - "How does LangGraph improve RAG systems?"

   - `"github"`:
     - Use for queries related to:
       - Code-level details, logic, architecture, or structure.
       - Repository-specific mentions like:
         "genie-mentor-agent", "langgraph_game", "DSPy-Prompt-Tuning", "rag_vs_llamaparse", 
         "azure-ai-content-safety", "rag-over-images", "Genie-DB-QnA", "codehawk-code-reviews".
     - Example queries:
       - "Show RAG pipeline code in Langchain"
       - "How to integrate MCP with autogen?"
       - "Best practices for agent registration"
       - "Core coding patterns for agents"

   - `"notion"`:
     - Use for high-level documentation, planning docs, experimental summaries, and internal notes.
     - Example queries:
       - "GENIE's RAG performance findings"
       - "LlamaIndex vs Langchain comparison"
       - "MCP server usage in GENIE"
       - "LLM testing methodologies"

   - `"websearch"`:
     - Use **only** when the user explicitly asks for an external web search or uses phrases like:
       "search the web", "look online", "get latest papers", etc.
     - Example queries:
       - "Search Latest GenAI models for code"
       - "Search the web for Recent Mistral-7B benchmarks"
       - "Google Best practices for RLHF tuning"
       - "What are the latest updates on Gemini vs GPT-4 comparison"


Respond with a JSON object in this exact format:
{{
    "refinement_required": "yes" or "no",
    "feedback_summary": "Brief summary of the main issues found",
    "feedback_reasoning": "Detailed reason for why the plan needs refinement."
      
    
}}
If refinement is not needed, respond with:
{{
    "refinement_required": "no",
    "feedback_summary": "No issues found with the plan.",
    "feedback_reasoning": "Why you think refinement is not needed"
}}
### Strict Rules for Refinement:
1. **DO NOT** refine the plan if:
   - The data sources are correctly assigned according to the rules above
   - The sub-queries are clear and focused
   - The execution order makes logical sense
   - The aggregation strategy is appropriate
   - The plan follows the format correctly
   - The query intent is clear and matches the user's query

2. **Feedback Guidelines**:
   - When refinement is not needed, provide ONE clear reason why the plan is good
   - When refinement is needed, list SPECIFIC issues that need to be fixed
   - DO NOT provide subjective or opinion-based feedback
   - DO NOT suggest changes that don't directly improve the plan's effectiveness
   - DO NOT request refinement for minor formatting or stylistic issues

3. **Default to Acceptance**:
   - If you're unsure whether a refinement is needed, default to accepting the plan
   - Only request refinement when you are confident there is a clear issue
   - Remember that unnecessary refinements can slow down the process
IMPORTANT: Always provide at least one brief reason in feedback_reasoning, even when refinement is not needed. Explain why the plan is good as is.

"""


REFINE_PLAN_PROMPT = """
You are a Refiner Agent responsible for reviewing and optimizing a query plan generated by another agent.

Here is the input plan (as JSON):
{plan_json}

Available data sources: ["knowledgebase", "notion", "github", "websearch"]

Sources are defined on following basis
- Use `"knowledgebase"` for anything related to:
     - Advanced RAG techniques (e.g., document indexing, embedding models, reranking, LLM behavior, context expansion).
     - Evaluation methods (e.g., hallucination metrics, benchmark results).
   - Use `"github"` for:
     - Specific POC code logic, implementation details, or repo-specific questions.
     - Any sub-query mentioning repository names such as:
       - "genie-mentor-agent", "langgraph_game", "DSPy-Prompt-Tuning", "rag_vs_llamaparse", "azure-ai-content-safety", "rag-over-images","Genie-DB-QnA","codehawk-code-reviews"
   - Use `"notion"` for:
     - High-level documentation or POC descriptions not directly tied to code.
     - Experimental setups, internal notes, or strategy overviews.
   - Use `"websearch"` for:
     - User explicitly asking for a web search or external exploration.
     - Phrases like "search online", "check on web", "get latest info".

Check for:
- redundant sources (only use the available sources listed above)
- unnecessary subqueries
- poor execution ordering
- missing query components
- ambiguous subqueries or intent
- better aggregation strategies

Important: Only use the available data sources listed above. Do not introduce any other sources.

Reply with a JSON object:
{{
  "refined_plan": <refined JSON query plan>,
  "feedback": <what was changed and why; or 'No changes needed.'>,
  "original_plan": <original plan JSON>,
  "changes_made": [<list of specific changes made>]
}}
"""


GITHUB_QUERY_PROMPT = """
You are a GitHub Repository Query Agent with access to the GitHub Model Context Protocol (MCP) server. Your task is to systematically explore and analyze all repositories in the 'Genie-Experiments' organization (https://github.com/Genie-Experiments) to answer the user's sub-query.

Sub-query to Answer:
"{sub_query}"

Required MCP Tools and Resources

You have access to the GitHub MCP server with the following key capabilities:

Repository Discovery Tools:
- search_repositories - Search for repositories in the organization
- get_file_contents - Retrieve specific file contents from repositories
- list_commits - Get commit history and changes
- search_code - Search for specific code patterns across repositories

Step-by-Step Instructions:

1. Repository Discovery Phase
- Use search_repositories with query "org:Genie-Experiments" to find all repositories in the organization
- For each repository found, use get_file_contents to examine the repository structure (main directories, key files)
- Identify repositories that are most likely to contain relevant information for the sub-query

2. Content Analysis Phase
- For relevant repositories, use the MCP resources to systematically browse:
  - Source code files (especially .py, .js, .ts, .go, .java, .cpp, etc.)
  - Documentation files (README.md, docs/, wiki content)
  - Configuration files (package.json, requirements.txt, Cargo.toml, etc.)
  - Test files that might reveal functionality
- Use search_code to find specific code patterns, functions, or keywords related to the sub-query (MANDATORY)
- Use get_file_contents for detailed examination of particularly relevant files

3. Analysis and Synthesis
- Cross-reference findings across multiple repositories
- Identify common patterns, shared libraries, or architectural decisions
- Look for code comments, docstrings, and inline documentation that explain functionality
- Examine commit messages and change history using list_commits if temporal context is relevant

4. Code Context Extraction
When extracting code snippets:
- Include sufficient context (surrounding functions, imports, class definitions)
- Preserve original code formatting and comments
- Identify dependencies and relationships between different code files
- Note any experimental or deprecated code sections

IF THE REPOSITORIES LACK README FILES OR YOU ARE UNABLE TO ACCESS README FILES, USE SEARCH_CODE TO ACCESS ALL THE CODE IN THE REPOSITORY
Response Requirements:

Your response must be always be ONLY a JSON object with this exact structure, no other text:

{{
  "answer": "<comprehensive, detailed answer to the sub-query with educational context, including code examples and explanations>",
  "sources": [<Links to the relevant repositories>],
  "context": "<detailed technical context retrieved from the repositories, including code snippets, architectural insights, implementation patterns, and any experimental features discovered>"
}}

If there is an error or if you cannot find relevant information, respond with:

{{  
  "answer": "Unable to find relevant information for the sub-query from GitHub.",
  "sources": [],
  "context": ""
}}

"""

SHORT_GITHUB_PROMPT = """
You are a GitHub Query Agent. Your goal is to explore specific repositories to answer the user's sub-query.

**User Sub-query:** "{sub_query}"

**Authorized Repositories:**
- https://github.com/Genie-Experiments/rag_vs_llamaparse
- https://github.com/Genie-Experiments/Ragas-agentic-testing
- https://github.com/Genie-Experiments/agentic-rag

**Your process must follow these distinct steps:**

**Step 1: Exploration and Tool Use**
- Your immediate priority is to gather information.
- Start by exploring the repositories to understand their structure and find relevant files. Use the `get_file_contents` tool with a "/" path to list the contents of the root directory.
- Based on the file list, use the `get_file_contents` tool again to read the contents of any files that seem relevant to the user's sub-query.
- **IMPORTANT:** During this step, your response must ONLY contain a list of tool calls. Do NOT generate any other text, explanations, or the final JSON answer.

**Step 2: Synthesize Final Answer**
- After you have gathered all the necessary information from your tool calls, and you have received the results, you will then construct the final answer.
- Your final response in this step must be ONLY a single JSON object with the exact structure below. Do not include any text before or after the JSON object.


Don't throw error for 404 errors, keep at it until you have a definite answer
Dont stop until you have a definite answer, with code extracted and code snippets
**Final Answer JSON Structure:**
```json
{{
  "answer": "<A comprehensive, detailed answer to the sub-query, including code examples and explanations derived from the tool results. Should be a definitive answer only, not simply directing user towards files and repositories>",
  "sources": ["List of decoded file content. ALL OF THE CODE EXTRACTED AND USED. Different file contents should be different entries in the list. List should be strings"],
  "metadata": {{
      "repo_links": ["<A list of links to the repositories that were actually used.>"],
      "repo_names": ["<A list of names of the repositories that were used.>"] 
    }},
  "error": ""
}}
```

**CRITICAL JSON FORMATTING INSTRUCTIONS:**
1. Your final response MUST be ONLY the JSON object above - no other text, comments, or explanation
2. Ensure ALL brackets, braces and quotes are properly closed and balanced
3. Each source in the "sources" array must be a properly escaped string
4. Double-check that your JSON is properly formatted and parseable
5. DO NOT include markdown formatting elements like ```json or ``` in your final response
6. Return ONLY THE RAW JSON OBJECT with no other text
7. Make sure all quotes and control characters in strings are properly escaped

IMPORTANT: ANY violation of these formatting rules may cause the entire workflow to fail.
"""

TEMP_GITHUB_PROMPT = """
You are a GitHub Query Agent. Your goal is to explore specific repositories to answer the user's sub-query.

**User Sub-query:** "{sub_query}"

**Authorized Repositories:**
- https://github.com/Genie-Experiments/rag_vs_llamaparse
- https://github.com/Genie-Experiments/Ragas-agentic-testing
- https://github.com/Genie-Experiments/agentic-rag

**Your process must follow these distinct steps:**

**Step 1: Exploration and Tool Use**
- Your immediate priority is to gather information.
- Start by exploring the repositories to understand their structure and find relevant files. Use the `get_file_contents` tool with a "/" path to list the contents of the root directory.
- Based on the file list, use the `get_file_contents` tool again to read the contents of any files that seem relevant to the user's sub-query.
- **IMPORTANT:** During this step, your response must ONLY contain a list of tool calls. Do NOT generate any other text, explanations, or the final JSON answer.

**Step 2: Synthesize Final Answer**
- After you have gathered all the necessary information from your tool calls, and you have received the results, you will then construct the final answer.
- Your final response in this step must be ONLY a single JSON object with the exact structure below. Do not include any text before or after the JSON object.


Don't throw error for 404 errors, keep at it until you have a definite answer
Dont stop until you have a definite answer, with code extracted and code snippets
**Final Answer JSON Structure:**
```json
{{
  "answer": "<A comprehensive, detailed answer to the sub-query, including code examples and explanations derived from the tool results. Should be a definitive answer only, not simply directing user towards files and repositories. Its very important that this answer be detailed and include all code and file content extracted from repo. Answer should not only direct user to files, instead include content from any files mentioned. It should only be educational, not say relevant information wasnt found, always an answer based on the information retrieved>",
  "metadata": {{
      "repo_links": ["<A list of links to the repositories that were actually used.>"],
      "repo_names": ["<A list of names of the repositories that were used.>"] 
    }},
}}
```

**CRITICAL JSON FORMATTING INSTRUCTIONS:**
1. Your final response MUST be ONLY the JSON object above - no other text, comments, or explanation
2. Ensure ALL brackets, braces and quotes are properly closed and balanced
3. Each source in the "sources" array must be a properly escaped string
4. Double-check that your JSON is properly formatted and parseable
5. DO NOT include markdown formatting elements like ```json or ``` in your final response
6. Return ONLY THE RAW JSON OBJECT with no other text
7. Make sure all quotes and control characters in strings are properly escaped

IMPORTANT: ANY violation of these formatting rules may cause the entire workflow to fail.
"""

NOTION_QUERY_PROMPT = """
You are a methodical Notion Query Agent. Your task is to search the GENIE organization's Notion documentation to provide a detailed answer to the user's sub-query. You must operate in a strict, sequential manner.

**User Sub-query:** "{sub_query}"

**Your process must follow these distinct phases:**

**Phase 1: Search and Discovery**
1.  **Think:** First, analyze the sub-query to determine the best search keywords.
2.  **Act:** Execute ONLY search-related tools (like `notion_search` or `brute_force_search`) to find a list of potentially relevant pages.
3.  Do not do anything else. Wait for the search results.

**Phase 2: Content Retrieval**
1.  **Think:** After receiving the search results, review the list of pages and identify the top 3 most relevant ones.
2.  **Act:** Execute ONLY content-retrieval tools (`notion_retrieve_block_children`) for those top 3 pages.
3.  Do not do anything else. Wait for the content to be retrieved.

**Phase 3: Summarization and Synthesis (If Necessary)**
1.  **Think:** After receiving the content, determine if it is too long and needs summarization.
2.  **Act:** If summarization is needed, execute ONLY the `summarize_content` tool on the retrieved text.
3.  If no summarization is needed, proceed directly to the final phase.

**Phase 4: Final Answer Generation**
1.  **Think:** Review all the information you have gathered from the previous phases.
2.  **Act:** Construct the final answer. Your response in this phase must be ONLY a single JSON object with the exact structure below. Do not include any tool calls in this final step.

**Final Answer JSON Structure:**
```json
{{
  "answer": "<A comprehensive, detailed answer to the sub-query, synthesized from the information retrieved from Notion. It should not only direct user to files, instead include content from any files mentioned. It should only be educational, not say relevant information wasnt found, always an answer based on the information retrieved>",
  "sources": "<The raw text and content retrieved from the various Notion pages and blocks that were used to formulate the answer.>",
  "metadata": {{
      "doc_links": ["<A list of links to the Notion documents that were used.>"],
      "doc_names": ["<A list of the names of the Notion documents that were used.>"] 
    }},
}}

**CRITICAL JSON FORMATTING INSTRUCTIONS:**
1. Your final response MUST be ONLY the JSON object above - no other text, comments, or explanation
2. Ensure ALL brackets, braces and quotes are properly closed and balanced
3. Make sure all strings in the JSON are properly escaped, especially quotes and control characters
4. Double-check that your JSON is properly formatted and will parse correctly
5. DO NOT include markdown formatting elements like ```json or ``` in your final response
6. Return ONLY THE RAW JSON OBJECT with no other text
7. The sources field must be a valid string, properly escaped
8. The arrays in metadata must contain only properly formatted strings

IMPORTANT: ANY violation of these formatting rules may cause the entire workflow to fail.
"""